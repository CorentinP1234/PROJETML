{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0940dee3-da11-4856-8bbe-709487661238",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2-Preparation des donnees\n",
    "Corentin PRADIE\n",
    "Lucas TAVANI\n",
    "Mehdi REMILI\n",
    "Romain VILLENEUVE\n",
    "L3C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15924ce-2225-4f4a-8a1d-f02212741570",
   "metadata": {},
   "source": [
    "La préparation des données, également appelée prétraitement des données ou nettoyage des données, est une étape cruciale du processus d'analyse de données et d'apprentissage automatique. Son but principal est d'améliorer la qualité et la fiabilité des données en éliminant les erreurs, les incohérences et les imprécisions qui pourraient affecter négativement les performances des modèles d'apprentissage automatique ou les résultats d'une analyse de données. Voici quelques objectifs spécifiques de la préparation des données :\n",
    "\n",
    "- Nettoyage des données : corriger ou supprimer les erreurs, les données manquantes ou les valeurs aberrantes qui pourraient fausser l'analyse.\n",
    "- Standardisation : harmoniser les données en utilisant des formats et des unités de mesure cohérents.\n",
    "- Transformation des données : convertir les données brutes en formats plus adaptés pour l'analyse ou l'apprentissage automatique, par exemple en créant de nouvelles variables à partir de variables existantes.\n",
    "- Intégration : combiner des données provenant de différentes sources pour créer un ensemble de données complet et cohérent.\n",
    "- Réduction de la dimensionnalité : sélectionner les variables les plus pertinentes pour l'analyse ou l'apprentissage automatique, en éliminant les redondances et les données non pertinentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9709e",
   "metadata": {},
   "source": [
    "Gridschearch expliquation (pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906104b-f1cb-4b0d-9d98-3d965d0a60be",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4d1dc1-5db2-4e9b-8dda-01af7a806947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304b5cb-a92f-4ec2-a509-9a6382d83026",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c889bdb-e816-4d12-bc1b-ee3d9c2c62ae",
   "metadata": {},
   "source": [
    "Nous avons trois datasets :\n",
    "- `data_x`: les données d'entrée\n",
    "- `data_y`: les données de sorties, c'est-à-dire la variation du prix de futures d'électricité pour les enregistrements de `data_x`\n",
    "- `dataNew_x` : les nouvelles données d'entrée a prédire (de meme format et de meme dimensions que data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aca19cc-0296-4ecf-af38-efe6a07dc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_x = pd.read_csv(\"data/Data_X.csv\", index_col='ID')\n",
    "raw_data_y = pd.read_csv(\"data/Data_Y.csv\", index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bac3d-aafc-4aa5-ae85-6f80da1c8d15",
   "metadata": {},
   "source": [
    "# Fusion des ensembles de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20425601-2659-48a4-a5c3-84c9e47b49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xy = pd.merge(raw_data_x, raw_data_y, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78153ddf-f9e8-4459-8baa-01994da66214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 35)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c61bcf-5318-48ea-8349-c4ee0dbca39a",
   "metadata": {},
   "source": [
    "Notre ensemble de données est composé de 1494 lignes et de 35 colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bfe565-bf62-40ae-af6d-b1344546666e",
   "metadata": {},
   "source": [
    "# Verification et Traitement des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e1fde4-31ec-4b3c-94ce-4395ce8d789f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xy.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5f65f-cd79-461b-a293-5bea22dc07ac",
   "metadata": {},
   "source": [
    "Il y a 1002 valeurs manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6820d95-5d0d-4f20-9cd1-025b71a38f11",
   "metadata": {},
   "source": [
    "## Verification des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32deaf0e-0807-4b26-9fe1-216ffd374d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DE_FR_EXCHANGE     25\n",
       "FR_DE_EXCHANGE     25\n",
       "DE_NET_EXPORT     124\n",
       "FR_NET_EXPORT      70\n",
       "DE_NET_IMPORT     124\n",
       "FR_NET_IMPORT      70\n",
       "DE_RAIN            94\n",
       "FR_RAIN            94\n",
       "DE_WIND            94\n",
       "FR_WIND            94\n",
       "DE_TEMP            94\n",
       "FR_TEMP            94\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_cols = data_xy.isna().sum()\n",
    "missing_values_cols = missing_values_cols[missing_values_cols != 0]\n",
    "missing_values_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b218bf-dd7d-4051-8171-02f84a2143d4",
   "metadata": {},
   "source": [
    "On observe que 12 variables possédent des valeurs manquantes.\n",
    "Au plus il manque 8% (124/1494) valeurs pour une variable.\n",
    "De plus, on observe des groupes de variables mesuré ensemble, c'est-a-dire, si une de ces variables est manquantes les autres variables du meme groupe seront manquantes aussi.<br> On observe les groupes suivant :\n",
    "- `DE_FR_EXCHANGE` et `FR_DE_EXCHANGE` : Si l'echange entre la France et l'Allemangne n'est pas mesuré ces deux variables seront manquantes.\n",
    "- `X_NET_IMPORT` et `X_NET_EXPORT` : Il se peut que pour certain jour les mesures de l'import et l'export ne soit pas disponibles pour un pays en particulier.\n",
    "-  `FR_RAIN`, `FR_WIND`, `FR_TEMP`, `DE_RAIN`, `DE_WIND`, `DE_TEMP` :  Il se peut que pour certain jour les mesures météorologiques ne soit pas disponibles pour les deux pays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169fcf4-4da8-4d75-a94d-bfdee5c857ae",
   "metadata": {},
   "source": [
    "## Vérification des lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f1252b2-f623-453f-8d12-47df5e8c3cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons 218 lignes contenant des valeurs manquantes\n"
     ]
    }
   ],
   "source": [
    "missing_values_rows = data_xy.isna().sum(axis=1)\n",
    "missing_values_rows = missing_values_rows[missing_values_rows != 0]\n",
    "print(f\"Nous avons {len(missing_values_rows)} lignes contenant des valeurs manquantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1086d1a9-b884-4e90-8809-52fcbe611a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum de valeurs manquantes par ligne :  2\n",
      "Maximum de valeurs manquantes par ligne :  6\n"
     ]
    }
   ],
   "source": [
    "min_missing_values_row = missing_values_rows.min()\n",
    "max_missing_values_row = missing_values_rows.max()\n",
    "print(\"Minimum de valeurs manquantes par ligne : \", min_missing_values_row)\n",
    "print(\"Maximum de valeurs manquantes par ligne : \", max_missing_values_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cee015-bd76-47d7-ab06-b7290c997cb8",
   "metadata": {},
   "source": [
    "### Regardons les variables manquantes dans une ligne contenant un minimum de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80376ba8-220d-4b60-8f69-2c06dfdca1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DE_NET_EXPORT    True\n",
       "DE_NET_IMPORT    True\n",
       "Name: 1054, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_idx = missing_values_rows.idxmin()\n",
    "min_missing_variables = data_xy.loc[min_idx].isna()\n",
    "min_missing_variables = min_missing_variables[min_missing_variables == True]\n",
    "min_missing_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d81561-937a-4dd2-9077-4e0159162699",
   "metadata": {},
   "source": [
    "En regardant une ligne contenant un minimum (non nulle) de valeurs manquantes, on observe le groupe `DE_NET_EXPORT` et `DE_NET_IMPORT`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7f5a6-d4b2-4dfb-b981-7a37b8461b95",
   "metadata": {},
   "source": [
    "### Regardons les variables manquantes dans une ligne contenant un minimum de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "161a783c-9642-413b-9b8f-e4d09f783bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DE_RAIN    True\n",
       "FR_RAIN    True\n",
       "DE_WIND    True\n",
       "FR_WIND    True\n",
       "DE_TEMP    True\n",
       "FR_TEMP    True\n",
       "Name: 1715, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx = missing_values_rows.nlargest(2).index\n",
    "max_missing_variables = data_xy.loc[max_idx[1]].isna()\n",
    "max_missing_variables = max_missing_variables[max_missing_variables == True]\n",
    "max_missing_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d3754f-33cf-4e48-b546-6aa2e30c21ea",
   "metadata": {},
   "source": [
    "En regardant une ligne contenant un minimum (non nulle) de valeurs manquantes, on observe le groupe des mesures météoroliques pour les deux pays.\n",
    "\n",
    "<br>\n",
    "On observe des variables manquantes dans 12 colonnes differentes. Les valeurs manquantes viennet de plusieurs groupes de variables mesurés ensemble.\n",
    "Les 208 lignes manquantes represente 208/1494 = 14% des lignes de notre ensemble de données. Le nombre de valeurs manquantes par lignes ou par colonnes ne justifie pas la suppresion de celles-ci.\n",
    "Nous pourrons imputer les valeurs manquantes par la moyenne, la médiane ou supprimer ces valeurs manquantes pour effectuer la modélisation des données.\n",
    "\n",
    "<br>Pour la suite de la préparation des donées, nous supprimons les données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde1dded-74f3-4b91-b792-9c538fd60ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supression des valeurs manquantes\n",
    "data_xy.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ebdba-c31f-43b1-abac-5ccd2e520b74",
   "metadata": {},
   "source": [
    "# Verification de la comparabilité "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6fc82c-acca-4f11-9897-270e0ce9e649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "|      | Min | Max |\n",
       "|------|-----|-----|\n",
       "| Mean | -0.577 (FR_NUCLEAR) | 0.771 (DE_GAS) |\n",
       "| Std  | 0.460 (FR_COAL) | 1.186 (FR_WINDPOW) |\n",
       "| Min  | -5.787 (FR_TEMP) | -0.795 (FR_COAL) |\n",
       "| Max  | 0.893 (DE_NUCLEAR) | 9.473 (FR_RAIN) |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calcul des statistiques et recherche du min et du max pour chaque statistique\n",
    "description = data_xy.drop(columns=['DAY_ID','TARGET']).describe().loc[['mean', 'std', 'min', 'max']]\n",
    "\n",
    "min_mean = description.loc['mean'].idxmin()\n",
    "max_mean = description.loc['mean'].idxmax()\n",
    "\n",
    "min_std = description.loc['std'].idxmin()\n",
    "max_std = description.loc['std'].idxmax()\n",
    "\n",
    "min_min = description.loc['min'].idxmin()\n",
    "max_min = description.loc['min'].idxmax()\n",
    "\n",
    "min_max = description.loc['max'].idxmin()\n",
    "max_max = description.loc['max'].idxmax()\n",
    "\n",
    "# Création de la table Markdown\n",
    "from IPython.display import Markdown\n",
    "\n",
    "markdown_table = f\"\"\"\n",
    "|      | Min | Max |\n",
    "|------|-----|-----|\n",
    "| Mean | {description.loc['mean', min_mean]:.3f} ({min_mean}) | {description.loc['mean', max_mean]:.3f} ({max_mean}) |\n",
    "| Std  | {description.loc['std', min_std]:.3f} ({min_std}) | {description.loc['std', max_std]:.3f} ({max_std}) |\n",
    "| Min  | {description.loc['min', min_min]:.3f} ({min_min}) | {description.loc['min', max_min]:.3f} ({max_min}) |\n",
    "| Max  | {description.loc['max', min_max]:.3f} ({min_max}) | {description.loc['max', max_max]:.3f} ({max_max}) |\n",
    "\"\"\"\n",
    "\n",
    "Markdown(markdown_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "508defc7-05ac-4312-beab-c928aaf6c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = data_xy.describe().loc[['mean', 'std', 'min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972c6234-294e-4b56-b64b-5aef23683d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "|      | Min | Max |\n",
       "|------|-----|-----|\n",
       "| Mean | -0.577 | 588.366 |\n",
       "| Std  | 0.460 | 342.279 |\n",
       "| Min  | -6.519 | 1.000 |\n",
       "| Max  | 0.893 | 1212.000 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_mean = description.loc['mean'].min()\n",
    "max_mean = description.loc['mean'].max()\n",
    "\n",
    "min_std = description.loc['std'].min()\n",
    "max_std = description.loc['std'].max()\n",
    "\n",
    "min_min = description.loc['min'].min()\n",
    "max_min = description.loc['min'].max()\n",
    "\n",
    "min_max = description.loc['max'].min()\n",
    "max_max = description.loc['max'].max()\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "markdown_table = f\"\"\"\n",
    "|      | Min | Max |\n",
    "|------|-----|-----|\n",
    "| Mean | {min_mean:.3f} | {max_mean:.3f} |\n",
    "| Std  | {min_std:.3f} | {max_std:.3f} |\n",
    "| Min  | {min_min:.3f} | {max_min:.3f} |\n",
    "| Max  | {min_max:.3f} | {max_max:.3f} |\n",
    "\"\"\"\n",
    "\n",
    "Markdown(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a1d93",
   "metadata": {},
   "source": [
    "Nous obeservons que les moyennes des différents variabkes ne sont pas du tout comparables. En effet V1 as une moyenne de 588 et V2 de -0,6. Celà rend les variables V1 et V2 inaptes as leur utilisation dans un modèle de machine learning. <br> Afin de régler ce problème il faut donc normaliser les variables. La phase de normalisation se déroulera dans les fichiers de création des différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dae528-67f7-4cc9-b214-57bb6b3d38d2",
   "metadata": {},
   "source": [
    "# Calcul de nouveaux attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c1e1ab-482c-4221-9650-b8961963a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xy['FR_PROD_RENEWABLE'] = data_xy['FR_SOLAR'] + data_xy['FR_HYDRO'] + data_xy['FR_WINDPOW'] + data_xy['FR_NUCLEAR']\n",
    "data_xy['DE_PROD_RENEWABLE'] = data_xy['DE_SOLAR'] + data_xy['DE_HYDRO'] + data_xy['DE_WINDPOW'] + data_xy['DE_NUCLEAR']\n",
    "\n",
    "data_xy['DE_PROD_FOSIL'] = data_xy['DE_COAL'] + data_xy['DE_GAS'] + data_xy['DE_LIGNITE']\n",
    "data_xy['FR_PROD_FOSSIL'] = data_xy['FR_COAL'] + data_xy['FR_GAS']\n",
    "\n",
    "data_xy['FR_CONS_RENEWABLE'] = data_xy['FR_CONSUMPTION'] - data_xy['FR_RESIDUAL_LOAD']\n",
    "data_xy['DE_CONS_RENEWABLE'] = data_xy['DE_CONSUMPTION'] - data_xy['DE_RESIDUAL_LOAD']\n",
    "\n",
    "data_xy['FR_TOTAL_PROD'] = data_xy['FR_GAS'] + data_xy['FR_COAL'] + data_xy['FR_HYDRO'] + data_xy['FR_NUCLEAR'] \\\n",
    "                            + data_xy['FR_SOLAR'] + data_xy['FR_WINDPOW']\n",
    "\n",
    "data_xy['DE_TOTAL_PROD'] = data_xy['DE_GAS'] + data_xy['DE_COAL'] + data_xy['DE_HYDRO'] + data_xy['DE_NUCLEAR'] \\\n",
    "                            + data_xy['DE_SOLAR'] + data_xy['DE_WINDPOW'] + data_xy['DE_LIGNITE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6b9fb",
   "metadata": {},
   "source": [
    "Dans la réalisation de modèle de machine learning il est parfois intéressant de créer de nouvelles features en combinant des variables existantes. Dans notre cas, nous avons trouvé intéressant de souligner la production (renouvelable, fossile et total) et la consomation pour chaque pays.\n",
    "\n",
    "Ces variables nous semblent pertinant car non seulement elles font sens d'un point de vue logique, mais elles sont aussi très faciles à calculer. De plus ces nouvelles variables nous permettent de concentrer plusieurs variables importantes en une, afin de maximiser l'efficacité du modèle.\n",
    "\n",
    "La création de ces nouveaux attributs se déroulera dans la partie 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100586c-bc6f-44d0-af3e-5fc7a52d1eee",
   "metadata": {},
   "source": [
    "# Separation France/ Allemagne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b521819c",
   "metadata": {},
   "source": [
    "En observant les données, nosu obsersions qu'il y as toujours deux observations avec les mêmes valeurs pour un même jour qui donnent un prix d'éléctricité (Y) différents. Celà nous amène donc à penser qu'il s'agit de mésures différents l'une pour la france et l'autre pour l'allemagne.\n",
    "\n",
    "Notre modèle de machine learning doit donc nous donner deux résultats différents pour les mêmes imputs. Nous n'avons donc pas d'autre choix que de réaliser deux modèles différents, l'un pour la France et l'autre pour l'Allemagne\n",
    "\n",
    "La séparation France Allemagne se fera juste avant la modélisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3831078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
