{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92197b08-47b1-43cd-81a4-8c97732ac087",
   "metadata": {},
   "source": [
    "# Machine Learning pour expliquer les variations journalières des prix des contrats à terme d'électricité en France et en Allemagne\n",
    "\n",
    "Dans ce notebook, nous allons analyser les facteurs influençant le prix de l'électricité en France et en Allemagne. Nous examinerons l'impact des variations climatiques, des matières premières et des échanges commerciaux sur les prix de l'électricité à court terme (24h). L'objectif est de construire un modèle de machine learning capable d'estimer avec précision les variations journalières des prix des contrats à terme sur l'électricité pour ces deux pays.\n",
    "\n",
    "Ce projet sera réalisé en suivant la méthodologie CRISP-DM, qui comprend les étapes suivantes:\n",
    "\n",
    "Business Understanding: Comprendre le contexte métier et les objectifs du projet.\n",
    "Data Understanding: Explorer et analyser les données fournies pour mieux comprendre leurs caractéristiques.\n",
    "Data Preparation: Préparer et nettoyer les données pour les adapter aux besoins du modèle de machine learning.\n",
    "Modelling: Entraîner différents modèles de machine learning et sélectionner le meilleur en fonction des performances.\n",
    "Evaluation: Évaluer les performances des modèles choisis et analyser les résultats pour en tirer des conclusions.\n",
    "Après cette introduction, nous entamerons la première étape, \"Business Understanding\", en détaillant davantage le contexte métier et les objectifs du projet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287ce6b-29fc-4a35-8da2-2f0d3a981fd6",
   "metadata": {},
   "source": [
    "### Table des matières\n",
    "\n",
    "1. [Objectif du projet](#chapter1)\n",
    "2. [Imports et fonctions d'aide](chapter2)\n",
    "3. [Description des données](#chapter2)\n",
    "4. [Préparation des données](#chapter3)\n",
    "5. [Modélisation des données](#chapter4)\n",
    "6. [Evaluation](#chapter5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff977ad-fbfc-4236-b6d1-90262e2f5e07",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Objectif du projet <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "Dans ce projet, nous cherchons à modéliser le prix de l'électricité à partir de données météorologiques, énergétiques (matières premières) et commerciales pour deux pays européens, la France et l'Allemagne. Le but est de construire un modèle capable d'estimer la variation journalière du prix des contrats à terme (futures) sur l'électricité, en France ou en Allemagne, à partir de ces variables explicatives. Ces contrats permettent d'acheter (ou de vendre) une quantité donnée d'électricité à un prix fixé par le contrat et qui sera livrée à une date future spécifiée (maturité du contrat). Les futures sont des instruments financiers qui donnent une estimation de la valeur de l'électricité au moment de la maturité du contrat à partir des conditions actuelles du marché.\n",
    "\n",
    "L'importance de ce projet réside dans la possibilité de mieux comprendre les facteurs qui influencent les prix de l'électricité et d'aider les parties prenantes à prendre des décisions éclairées concernant l'achat, la vente ou la production d'électricité. En comprenant les facteurs qui influencent les prix de l'électricité, les entreprises et les gouvernements peuvent optimiser leurs stratégies énergétiques et leurs politiques pour réduire les coûts et favoriser le développement durable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a203444-2419-4588-a5a6-734b916d4062",
   "metadata": {},
   "source": [
    "## 2. Imports et fonctions d'aide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a554975-f949-4b92-9a55-6693ae5f1b85",
   "metadata": {},
   "source": [
    "### 2.1 Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ea0203-1cdf-4a47-8921-525445dbb9bb",
   "metadata": {},
   "source": [
    "Nous allons utiliser les bibliothèque \n",
    "- **Pandas** et **Numpy** pour la manipulation des données\n",
    "- **Matplotlib** et **Seabron** pour la visualisation des données\n",
    "- **Scikit-learn** pour la modelisation des données\n",
    "- **IPython.display** pour afficher du texte formaté en Markdown et LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609c3c8f-a4b2-4787-a6c9-eca4353ecde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "# Configuration de l'affichage des graphiques dans le notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de84f3-fa60-4566-b7a0-c223b338b3a8",
   "metadata": {},
   "source": [
    "### 2.2 fonctions d'aide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8191d512-7996-40fc-803c-59f02170b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour afficher le texte en utilisant le formatage Markdown\n",
    "def display_m(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799e0504-0025-4b46-8ffc-2944a3e85047",
   "metadata": {},
   "source": [
    "## 3. Description des données <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09664892-e1c7-4910-99bd-74a09049b8a5",
   "metadata": {},
   "source": [
    "### 3.1 Chargement des données intiales\n",
    "Nous avons trois datasets au format csv:\n",
    "- **Data_x**: les données d'entrée\n",
    "- **Data_y**: les données de sorties (labels)\n",
    "- **DataNew_x**: les nouvelles données d'entrée a prédire (de meme format et dimensions que data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed9b461-6cf6-4ccd-b3cc-ff3d29e21bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = pd.read_csv(\"data/Data_X.csv\")\n",
    "dataNew_x = pd.read_csv(\"data/DataNew_X.csv\")\n",
    "data_y = pd.read_csv(\"data/Data_Y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777414ce-f285-4005-8a8a-4d65b773c5f3",
   "metadata": {},
   "source": [
    "### 3.2 Description des variables des datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8229f91-9924-4938-833f-50867e8a732e",
   "metadata": {},
   "source": [
    "#### 3.2.1 Description des variables des datasets d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f566ed0-c56c-465d-86aa-0f4b6eade894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Les dataset d'entrée **Data_x** et **DataNew_x** sont composés de **1494** et **654** entrées respectivement avec **35** variables."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vars_description import x_vars_desc\n",
    "\n",
    "nbr_columns_x = len(x_vars_desc)\n",
    "\n",
    "display_m(f\"Les dataset d'entrée **Data_x** et **DataNew_x** sont composés de **{len(data_x)}** et **{len(dataNew_x)}**\\\n",
    " entrées respectivement avec **{nbr_columns_x}** variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ae0fb2-b694-458d-bfd6-86871fb5087a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Descriptions des **35** variables de **Data_x** et de **DataNew_x**:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| Colonne | Description |\n",
       "| --- | --- |\n",
       "| ID | Identifiant unique pour chaque entrée |\n",
       "| DAY_ID | Date de l'entrée sous forme numérique |\n",
       "| COUNTRY | Pays concerné par l'entrée - DE = Allemagne, FR = France |\n",
       "| DE_CONSUMPTION | Consommation d'électricité en Allemagne |\n",
       "| FR_CONSUMPTION | Consommation d'électricité en France |\n",
       "| DE_FR_EXCHANGE | Electricité échangée entre Allemagne et France |\n",
       "| FR_DE_EXCHANGE | Electricité échangée entre France et Allemagne |\n",
       "| DE_NET_EXPORT | Electricité exportée par l'Allemagne vers l'Europe |\n",
       "| FR_NET_EXPORT | Electricité exportée par la France vers l'Europe |\n",
       "| DE_NET_IMPORT | Electricité importée en Allemagne depuis l'Europe |\n",
       "| FR_NET_IMPORT | Electricité importée en France depuis l'Europe |\n",
       "| DE_GAS | Volume de gaz naturel consommé en Allemagne |\n",
       "| FR_GAS | Volume de gaz naturel consommé en France |\n",
       "| DE_COAL | Volume de charbon consommé en Allemagne |\n",
       "| FR_COAL | Volume de charbon consommé en France |\n",
       "| DE_HYDRO | Production d'électricité d'origine hydraulique en Allemagne |\n",
       "| FR_HYDRO | Production d'électricité d'origine hydraulique en France |\n",
       "| DE_NUCLEAR | Production d'électricité d'origine nucléaire en Allemagne |\n",
       "| FR_NUCLEAR | Production d'électricité d'origine nucléaire en France |\n",
       "| DE_SOLAR | Production d'électricité d'origine photovoltaïque en Allemagne |\n",
       "| FR_SOLAR | Production d'électricité d'origine photovoltaïque en France |\n",
       "| DE_WINDPOW | Production d'électricité d'origine éolienne en Allemagne |\n",
       "| FR_WINDPOW | Production d'électricité d'origine éolienne en France |\n",
       "| DE_LIGNITE | Volume de lignite consommé en Allemagne |\n",
       "| DE_RESIDUAL_LOAD | Electricité consommée après utilisation des énergies renouvelables en Allemagne |\n",
       "| FR_RESIDUAL_LOAD | Electricité consommée après utilisation des énergies renouvelables en France |\n",
       "| DE_RAIN | Quantité de pluie tombée en Allemagne |\n",
       "| FR_RAIN | Quantité de pluie tombée en France |\n",
       "| DE_WIND | Vitesse du vent en Allemagne |\n",
       "| FR_WIND | Vitesse du vent en France |\n",
       "| DE_TEMP | Température en Allemagne |\n",
       "| FR_TEMP | Température en France |\n",
       "| GAS_RET | Prix journalier du gaz naturel en Europe |\n",
       "| COAL_RET | Prix journalier du charbon en Europe |\n",
       "| CARBON_RET | Prix journalier des émissions de carbone en Europe |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Affichage des descriptions des colonnes pour Data_x\n",
    "display_m(f\"Descriptions des **{nbr_columns_x}** variables de **Data_x** et de **DataNew_x**:\")\n",
    "table_header = \"| Colonne | Description |\\n| --- | --- |\"\n",
    "table = \"\\n\".join([f\"| {col} | {desc} |\" for col, desc in x_vars_desc.items()])\n",
    "display_m(table_header + \"\\n\" + table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d0d63-a511-4f62-a9ea-1dbcd5f00a4f",
   "metadata": {},
   "source": [
    "#### 3.2.2 Description des variables du datasets de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63719cf-45a2-483f-b695-9e2f1c410f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Le dataset de sortie **Data_y** est composé de **1494** entrées avec **2** variables."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vars_description import y_vars_desc\n",
    "\n",
    "nbr_columns_y = len(y_vars_desc)\n",
    "\n",
    "display_m(f\"Le dataset de sortie **Data_y** est composé de **{len(data_x)}** entrées \\\n",
    "avec **{nbr_columns_y}** variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff223f8-0525-49e5-96e5-51ecb2446838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<br>Descriptions des **2** variables de **Data_y**:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| Colonne | Description |\n",
       "| --- | --- |\n",
       "| ID | Identifiant unique pour chaque entrée |\n",
       "| TARGET | Variation journalière du prix de futures d'électricité (maturité 24h) |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "# Affichage des descriptions des colonnes pour Data_x\n",
    "display_m(f\"<br>Descriptions des **{nbr_columns_y}** variables de **Data_y**:\")\n",
    "table_header = \"| Colonne | Description |\\n| --- | --- |\"\n",
    "table = \"\\n\".join([f\"| {col} | {desc} |\" for col, desc in y_vars_desc.items()])\n",
    "display_m(table_header + \"\\n\" + table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83490de0-60f1-47d4-9a71-976c61a3f29c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e03d4-885a-40b2-8f74-ad63372a07a6",
   "metadata": {},
   "source": [
    "### 4.1 Classement des enregistrement par ID et mise a jour de l'index sur la colonne ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18443a68-4e2d-47ad-96f6-2badd3fb9d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data_x.sort_values(by='ID').reset_index(drop=True)\n",
    "dataNew_x = dataNew_x.sort_values(by='ID').reset_index(drop=True)\n",
    "data_y = data_y.sort_values(by='ID').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef46e07-9a2e-4b82-a6cd-131aa512e7ef",
   "metadata": {},
   "source": [
    "### 4.2 Concatenation de Data_x et de DataNew_x\n",
    "Pour les prochaines etapes de preparation, nous avons besoin de regrouper les dataset d'entrée **Data_x** et **DataNew_x**.\n",
    "Nous ajoutons une nouvelle variable catégorielle binaire **New** pour pouvoir identifier l'origine des enregistrements venant de **Data_x** ou **DataNew_x**.\n",
    "Nous allons utiliser la méthode **concat()** de la bibliotheque pandas pour regrouper les dataset d'entrée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24d81bd-94ae-4d7b-b641-8e4d34b41edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une colonne 'New' à chaque DataFrame\n",
    "# Dans le but de pouvoir les identifier apres la concaténation\n",
    "data_x['New'] = True\n",
    "dataNew_x['New'] = False\n",
    "\n",
    "# Concaténation les deux DataFrames\n",
    "all_data_x = pd.concat([data_x, dataNew_x], ignore_index=True).sort_values(by='ID').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2dc220-87f9-4f53-ac93-13144c7d2cff",
   "metadata": {},
   "source": [
    "### 4.3 Fonction de recuperation des sous-datasets\n",
    "Nous avons deux fonctions pour récupérer les sous-datasets à partir du dataset concaténé all_data_x. Ces fonctions permettent de sélectionner les données en fonction de l'origine des enregistrements (Data_x ou DataNew_x) et de filtrer les données par pays (FR ou DE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5bf076-537e-4f51-9d04-77fe0da23430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour recuperer le sous-dataset Data_x\n",
    "def get_data_x(all_data_x, country=None):\n",
    "    data_x = all_data_x[all_data_x['New'] == True].drop(columns=['New']).sort_values(by='ID').reset_index(drop=True)\n",
    "    if country == 'FR':\n",
    "        return data_x[data_x['COUNTRY'] == 'FR']\n",
    "    elif country == 'DE':\n",
    "        return data_x[data_x['COUNTRY'] == 'DE']\n",
    "    return data_x\n",
    "\n",
    "# Fonction pour recuperer le sous-dataset DataNew_x\n",
    "def get_dataNew_x(all_data_x, country=None):\n",
    "    dataNew_x = all_data_x[all_data_x['New'] == False].drop(columns=['New']).sort_values(by='ID').reset_index(drop=True)\n",
    "    if country == 'FR':\n",
    "        return dataNew_x[dataNew_x['COUNTRY'] == 'FR']\n",
    "    elif country == 'DE':\n",
    "        return dataNew_x[dataNew_x['COUNTRY'] == 'DE']\n",
    "    return dataNew_x\n",
    "\n",
    "# Fonction pour récupérer le sous-dataset par pays\n",
    "def get_all_data_x_by_country(all_data_x, country):\n",
    "    if country == 'FR':\n",
    "        return all_data_x[all_data_x['COUNTRY'] == 'FR'].drop(columns=['New'])\n",
    "    elif country == 'DE':\n",
    "        return all_data_x[all_data_x['COUNTRY'] == 'DE'].drop(columns=['New'])\n",
    "    else:\n",
    "        print(\"Error in get_all_data_x_by_country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e874126-c8f0-4fdc-a73b-63f589b222a9",
   "metadata": {},
   "source": [
    "### 4.4 Vérification des fonctions de récupération des sous-datasets \n",
    "Dans cette partie, nous réalisons des tests pour vérifier que les fonctions **get_data_x()**, **get_dataNew_x()** et **get_all_data_x_by_country()** fonctionnent correctement. Nous comparons les sous-datasets obtenus en utilisant ces fonctions avec les sous-datasets d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c96463aa-8353-4638-bd8b-91850a943cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Test de **get_data_x** pour Data_x et DataNew_x:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Test pour 'FR'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Test pour 'DE'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Test pour **get_all_data_x_by_country** avec 'FR'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Test pour **get_all_data_x_by_country** avec 'DE':"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_m(\"Test de **get_data_x** pour Data_x et DataNew_x:\")\n",
    "data_x_from_function = get_data_x(all_data_x)\n",
    "data_x_tmp = data_x.drop(columns=['New'])\n",
    "\n",
    "display(data_x_tmp.equals(data_x_from_function))\n",
    "\n",
    "display_m(\"Test pour 'FR'\")\n",
    "data_x_FR = data_x[data_x['COUNTRY'] == 'FR'].drop(columns=['New'])\n",
    "data_x_from_function_FR = get_data_x(all_data_x, country='FR')\n",
    "\n",
    "display(data_x_FR.equals(data_x_from_function_FR))\n",
    "\n",
    "display_m(\"Test pour 'DE'\")\n",
    "data_x_DE = data_x[data_x['COUNTRY'] == 'DE'].drop(columns=['New'])\n",
    "data_x_from_function_DE = get_data_x(all_data_x, country='DE')\n",
    "\n",
    "display(data_x_DE.equals(data_x_from_function_DE))\n",
    "\n",
    "display_m(\"Test pour **get_all_data_x_by_country** avec 'FR'\")\n",
    "all_data_x_FR = all_data_x[all_data_x['COUNTRY'] == 'FR'].drop(columns=['New'])\n",
    "all_data_x_from_function_FR = get_all_data_x_by_country(all_data_x, country='FR')\n",
    "\n",
    "display(all_data_x_FR.equals(all_data_x_from_function_FR))\n",
    "\n",
    "display_m(\"Test pour **get_all_data_x_by_country** avec 'DE':\")\n",
    "all_data_x_DE = all_data_x[all_data_x['COUNTRY'] == 'DE'].drop(columns=['New'])\n",
    "all_data_x_from_function_DE = get_all_data_x_by_country(all_data_x, country='DE')\n",
    "\n",
    "display(all_data_x_DE.equals(all_data_x_from_function_DE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3cb23-2080-40a2-a65f-9dbabc47805b",
   "metadata": {},
   "source": [
    "### 4.5 Vérification et traitement des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f08df-6ab1-42cc-9cd4-fa46b27489bd",
   "metadata": {},
   "source": [
    "#### 4.1.1 Vérification des valeurs manquantes de des datasets d'entrée **Data_x** et **DataNew_x**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c34ce-530f-4463-912d-145b805429d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du nombre \n",
    "missing_values_x = data_x.isnull().sum()\n",
    "missing_values_x.loc[missing_values_x != 0]\n",
    "print(\"NOOOOOOOOOOO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb1d70-ed18-4d7e-893a-53319b3b0afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du nombre de valeurs manquantes pour chaque colonnes de data_new_x\n",
    "missing_values_new_x = dataNew_x.isnull().sum()\n",
    "missing_values_new_x.loc[missing_values_x != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ccb304-fddb-4882-b9fa-29e1e344bd9a",
   "metadata": {},
   "source": [
    "On observe que ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b8d40-a561-4a8b-bdfc-4a6c589381c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count_per_row = data_x.isnull().sum(axis=1)\n",
    "\n",
    "max_nan_count_per_row = nan_count_per_row.max()\n",
    "display_m(f\"L'enregistrement comptant le plus de valeur manquante compte **{max_nan_count_per_row}** valeurs manquantes sur 35 valeurs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb37e8e-c658-4fff-a748-32ce08ecc055",
   "metadata": {},
   "source": [
    "On observe qu'au maximum une variable peut manquer a **124** enregistrement (sur 1494) et qu'au plus un enregistrement peut manquer **6** valeurs (sur 35).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16713604-f500-4bc2-b709-d14dba349daa",
   "metadata": {},
   "source": [
    "#### 4.1.2 Traitement des valeurs manquantes de des datasets d'entrée **Data_x** et **DataNew_x**\n",
    "\n",
    "Nous allons remplacer les valeurs manquantes par la moyenne de la colonne en question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385bd4d3-486d-4573-a0f4-9c6d1e396cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns in Data_x\n",
    "numeric_cols_x = data_x.select_dtypes(include=np.number).columns.tolist()\n",
    "data_x[numeric_cols_x] = data_x[numeric_cols_x].fillna(data_x[numeric_cols_x].mean())\n",
    "\n",
    "# Select only numeric columns in DataNew_x\n",
    "numeric_cols_new_x = dataNew_x.select_dtypes(include=np.number).columns.tolist()\n",
    "dataNew_x[numeric_cols_new_x] = dataNew_x[numeric_cols_new_x].fillna(dataNew_x[numeric_cols_new_x].mean())\n",
    "\n",
    "# Afficher le nombre de valeurs manquantes dans Data_x\n",
    "display_m(f\"Nombre de valeurs manquantes dans **Data_x** :\\n{data_x.isnull().sum().sum()}\")\n",
    "\n",
    "# Afficher le nombre de valeurs manquantes dans DataNew_x\n",
    "display_m(f\"Nombre de valeurs manquantes dans **DataNew_x** :\\n{dataNew_x.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bec212-0fc2-4bef-86e8-54a1ae81c58a",
   "metadata": {},
   "source": [
    "#### 4.1.3 Verification des valeurs manquantes du dataset de sortie **Data_y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd482316-7458-4e46-87a8-f8dd2683dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_m(f\"Nombre de valeurs manquantes dans **Data_y** :\\n{data_y.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea30d2-befe-4b79-b236-aad5603eeae2",
   "metadata": {},
   "source": [
    "### 4.2 Verification de la comparabilité des variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863131a-7a7c-4ebd-8321-6b790dcbc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_x(all_data_x, country=None):\n",
    "    data_x = \n",
    "    if country == 'FR':\n",
    "        return data_x[data_x['COUNTRY'] == 'FR']\n",
    "    elif country == 'DE':\n",
    "        return data_x[data_x['COUNTRY'] == 'DE']\n",
    "    return data_X\n",
    "\n",
    "def get_dataNew_x(all_data_x, country=None):\n",
    "    dataNew_x = all_data_x[all_data_x['New'] == 1].drop(columns=['New']).sort_values(by='ID').reset_index(drop=True)\n",
    "    if country == 'FR':\n",
    "        return dataNew_x[dataNew_x['COUNTRY'] == 'FR']\n",
    "    elif country == 'DE':\n",
    "        return dataNew_x[dataNew_x['COUNTRY'] == 'DE']\n",
    "    return dataNew_x\n",
    "\n",
    "# Ajouter une colonne 'New' à chaque DataFrame\n",
    "data_x['New'] = 0\n",
    "dataNew_x['New'] = 1\n",
    "\n",
    "# Concaténer les deux DataFrames\n",
    "all_data_x = pd.concat([data_x, dataNew_x], ignore_index=True).sort_values(by='ID')\n",
    "\n",
    "dat_x = data_x[data_x['COUNTRY'] == 'FR'].drop(columns=['New'])\n",
    "                \n",
    "dat_x_bis = get_data_x(all_data_x, country='FR')\n",
    "\n",
    "display(dat_x_bis.iloc[0].equals(dat_x.iloc[0]))\n",
    "display(dat_x)\n",
    "# dat_x_bis['COUNTRY'] = 'ANG'\n",
    "# display(dat_x_bis.iloc[0].equals(dat_x.iloc[0]))\n",
    "# dat_x['COUNTRY'] = 'ANG'\n",
    "# display(dat_x_bis.iloc[0].equals(dat_x.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a9790-7c00-4dc7-b614-a30d04ae8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une colonne 'New' à chaque DataFrae\n",
    "data_x['New'] = 0\n",
    "dataNew_x['New'] = 1\n",
    "\n",
    "# Concaténer les deux DataFrames\n",
    "all_data_x = pd.concat([data_x, dataNew_x], ignore_index=True)\n",
    "\n",
    "# Obtenir le sous-ensemble de all_data_x où New = 0 et supprimer la colonne 'New'\n",
    "subset_all_data_x = all_data_x[all_data_x['New'] == 0].drop(columns=['New'])\n",
    "\n",
    "# Afficher le résultat\n",
    "print(subset_all_data_x.equals(data_x.drop(columns=['New'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53621442-8696-4656-97fd-a7a7cebb8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténer les deux datasets d'entrée verticalement\n",
    "all_data_x = pd.concat([data_x, dataNew_x], axis=0)\n",
    "\n",
    "# Grouper les données par DAY_ID et COUNTRY, puis compter le nombre d'enregistrements pour chaque groupe\n",
    "grouped_data = all_data_x.groupby(['DAY_ID', 'COUNTRY']).size().reset_index(name='count')\n",
    "\n",
    "# Vérifier si un groupe a plus d'un enregistrement\n",
    "duplicate_rows = grouped_data[grouped_data['count'] > 1]\n",
    "\n",
    "if duplicate_rows.empty:\n",
    "    print(\"Il n'y a jamais plus d'un enregistrement FR ou DE pour le même jour (DAY_ID).\")\n",
    "else:\n",
    "    print(\"Il y a des enregistrements FR ou DE en double pour le même jour (DAY_ID) :\")\n",
    "    print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bfdaf3-691f-4bfb-89b4-49abc415cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouper les données par DAY_ID et COUNTRY\n",
    "grouped_data = all_data_x.groupby(['DAY_ID', 'COUNTRY'])\n",
    "\n",
    "# Vérifier si les valeurs des lignes pour COUNTRY=FR et COUNTRY=DE sont égales (hors colonne COUNTRY)\n",
    "equal_values = True\n",
    "\n",
    "for day_id, day_group in grouped_data:\n",
    "    fr_data = day_group.loc[day_group['COUNTRY'] == 'FR']\n",
    "    de_data = day_group.loc[day_group['COUNTRY'] == 'DE']\n",
    "\n",
    "    # Si les deux lignes COUNTRY=FR et COUNTRY=DE existent, comparez leurs valeurs\n",
    "    if not fr_data.empty and not de_data.empty:\n",
    "        if not fr_data.drop(columns=['COUNTRY']).equals(de_data.drop(columns=['COUNTRY'])):\n",
    "            equal_values = False\n",
    "            break\n",
    "\n",
    "if equal_values:\n",
    "    print(\"Toutes les valeurs de la ligne COUNTRY=FR et de la ligne COUNTRY=DE sont égales (hors la colonne COUNTRY) pour chaque jour DAY_ID.\")\n",
    "else:\n",
    "    print(\"Les valeurs de la ligne COUNTRY=FR et de la ligne COUNTRY=DE ne sont pas toujours égales (hors la colonne COUNTRY) pour chaque jour DAY_ID.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4628cda3-dd0d-4798-a315-379c83ae9cde",
   "metadata": {},
   "source": [
    "### 4.3 Separation des datasets entre la France et l'Allemagne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9c80b-b968-44af-b193-ecdf16394915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22266d4b-b413-447b-9788-51f464a403a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999bc39-5289-4ff7-8722-ef9ced554d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05ea7c32-1862-40fc-a0ab-71d4b40e38fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f78db76-7a55-478b-8b12-6ab0a21f648b",
   "metadata": {},
   "source": [
    "#### 4.2.1 Distribution et échelle des variables d'entrée\n",
    "Nous allons visualiser la distribution des variables d'entrée en utilisant des histogrammes et des boîtes à moustaches (boxplots) pour évaluer leur distribution, leur centralité et leur dispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e7eec-6b25-4a25-944c-17cca60ffc42",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Effectuer des tests statistiques\n",
    "from scipy import stats\n",
    "# Effectuer un test t de Student entre deux colonnes\n",
    "stats.ttest_ind(data_x['colonne1'], data_x['colonne2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922858c-e1c5-43e6-a7bc-5dada50a377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_subset = data_x.drop(columns=['ID'])\n",
    "\n",
    "# Affichage des histogrammes pour chaque variable d'entrée\n",
    "data_x_subset.hist(figsize=(20, 20))\n",
    "plt.show()\n",
    "\n",
    "# Affichage des boxplots pour chaque variable d'entrée\n",
    "data_x_subset.plot(kind='box', subplots=True, layout=(7, 5), figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe7248-4456-4712-b17e-134b6e2fa4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
